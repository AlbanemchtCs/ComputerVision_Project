# :globe_with_meridians: Projet Noise2Noise DeepLearning et ComputerVision
Projet pour les cours de DeepLearning et ComputerVision Ã  CentraleSupÃ©lec.

Le dataset du projet se trouve sur [GoogleDrive](https://drive.google.com/drive/folders/1ibHySGXsBqP30s7mwOPyFWa1eA8NYo2J?usp=sharing).

## ğŸ¯ Objectifs
Le but de ce projet du cours de Computer Vision est de poursuivre le projet de DeepLearning par lâ€™application de mÃ©thodes de ComputerVision (filtres, rÃ©entrainement du modÃ¨le et poursuite de la data augmentation), pour amÃ©liorer nos rÃ©sultats obtenus.  

Le but de ce projet des cours Deep Learning et ComputerVision est dâ€™implÃ©menter un modÃ¨le similaire au [Noise2Noise](https://arxiv.org/pdf/1803.04189.pdf), un rÃ©seau de dÃ©bruitage dâ€™images entraÃ®nÃ© sans image de rÃ©fÃ©rence propre.   

[Kaggle](https://www.kaggle.com/datasets/mehrdadkianiosh/noisy-images?resource=download) mettant Ã  disposition un dataset basÃ© sur le papier original, lâ€™objectif est dâ€™Ã©tudier et dâ€™implÃ©menter diffÃ©rentes architectures de rÃ©seaux de neurones afin de vÃ©rifier les affirmations et rÃ©sultats du papier original. Le code des auteurs se basant sur TensorFlow, le framework PyTorch est ici utilisÃ© comme alternative.

## :page_facing_up: Description
Avec Noise2Noise, les auteurs souhaitent tirer parti des DNN (deep neural networks) pour Ã©viter la modÃ©lisation de vraisemblance statistique explicite prÃ©alable des images bruitÃ©es et Ã  la place apprendre Ã  mettre en correspondance les images bruitÃ©es avec les images propres non observÃ©es. 

En particulier, le dÃ©bruitage peut Ãªtre rÃ©alisÃ© en utilisant uniquement des images bruitÃ©es, si le bruit est additif et non biaisÃ©. En dâ€™autres termes, il est possible, Ã  partir des donnÃ©es dâ€™apprentissage sur deux images bruitÃ©es de maniÃ¨re indÃ©pendante, dâ€™apprendre indirectement le modÃ¨le de vraisemblance statistique explicite de la corruption sans se baser sur un modÃ¨le de dÃ©bruitage qui utilise des images propres.

## ğŸ¤” Choix techniques
Deux modÃ¨les ont Ã©tÃ© implÃ©mentÃ©s : un Resnet et un U-Net. Ces deux derniers dÃ©coulent de lâ€™architecture Noise2Noise du papier original. 

Un rÃ©seau discriminant a Ã©galement Ã©tÃ© implÃ©mentÃ© pour pouvoir comparer la performance entre un dÃ©bruiteur avec un training discriminant (avec une image propre) et les deux rÃ©seaux Noise2Noise dÃ©ployÃ©s, pour valider l'hypothÃ¨se du papier original qui montre quâ€™en restaurant des images en ne regardant que des exemples corrompus produit des performances Ã©gales, voire supÃ©rieures, Ã  celles obtenues en utilisant des donnÃ©es propres. 

Une augmentation des donnÃ©es a Ã©tÃ© rÃ©alisÃ© sur l'ensemble des trois modÃ¨les pour amÃ©liorer notre performance globale des modÃ¨les, basÃ©e sur la mÃ©trique PSNR (Peak Signal Noise Ratio), exprimÃ©e en dÃ©cibel (dB). Le PSNR permet de quantifier la performance des modÃ¨les en mesurant la qualitÃ© de reconstruction de lâ€™image compressÃ©e par rapport Ã  lâ€™image propre.

DiffÃ©rentes mÃ©thodes de Computer Vision ont Ã©tÃ© implÃ©mentÃ©es dans le but d'amÃ©liorer notre PSNR moyen final aprÃ¨s entraÃ®nement sur notre rÃ©seau U-Net ayant eu la meilleure performance : mise en oeuvre de six filtres (mÃ©dian, gaussien, bilatÃ©ral, unsharp masking, unsharp masking & mÃ©dian et nagao), un rÃ©entrainement de notre modÃ¨le et un gÃ©nÃ©rateur d'augmentation des donnÃ©es.

## :card_index_dividers: Segmentation
Notre rÃ©pertoire est segmentÃ© en 5 fichiers jupyter notebooks, 3 fichiers .pth, deux fichiers markdown, un fichier .gitinore et un fichier texte pour les requirements :

```bash 
.
â”œâ”€â”€ README.md
â”œâ”€â”€ CONTRIBUTING.md
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt 
â”œâ”€â”€ Networks
â”‚     â”œâ”€â”€ Noise2Noise_ResNet.ipynb
â”‚     â”œâ”€â”€ parameters_models_Resnet.pth
â”‚     â”œâ”€â”€ Noise2Noise_UNet.ipynb
â”‚     â”œâ”€â”€ parameters_models_UNet.pth
â”‚     â”œâ”€â”€ Inverse_Noise2Noise_Discriminative.ipynb
â”‚     â””â”€â”€ parameters_models_Discriminative.pth
â””â”€â”€ Preprocessing
      â”œâ”€â”€ Data_augmentation.ipynb
      â””â”€â”€ filters.ipynb


```

- ``README.md`` contient l'ensemble des informations sur le projet pour pouvoir l'installer.
- ``CONTRIBUTING.md`` contient l'ensemble des informations sur les normes et les pratiques de collaboration et de gestion du projet.
- ``.gitignore`` contient les fichiers qui doivent Ãªtre ignorÃ©s lors de l'ajout de fichiers au dÃ©pÃ´t Git.
- ``requirements.txt`` contient la liste des modules et des bibliothÃ¨ques Python qui doivent Ãªtre installÃ©s, ainsi que leur version spÃ©cifique.
- ``Networks`` contient l'ensemble des jupyter notebooks de nos rÃ©seaux implÃ©mentÃ©s ``Noise2Noise_ResNet.ipynb``, ``Noise2Noise_UNet.ipynb`` et ``Inverse_Noise2Noise_Discriminative.ipynb``, ainsi que les fichiers de sauvegarde des paramÃ¨tres du dernier training de chaque modÃ¨le ``parameters_models_Resnet.pth``, ``parameters_models_UNet.pth`` et ``parameters_models_Discriminative.pth``.
- ``Preprocessing`` contient le jupyter notebook ``Data_augmentation.ipynb`` qui permet de gÃ©nÃ©rer les fichiers augmentÃ©s pour le training set et validation set (utilisÃ© comme training set dans le rÃ©seau discriminatif) et le jupyter notebook ``filters.ipynb`` qui permet de gÃ©nÃ©rer les fichiers pickle avec la mise en oeuvre des filtres sur les images d'entrÃ©e pour le training set et le validation set.

## :wrench: Installation
Pour lancer, nous vous recommandons sur un terminal uniquement :

1. Tout d'abord, assurez-vous que vous avez installÃ© une version `python` supÃ©rieure Ã  3.10. Nous vous conseillons un environnement conda avec la commande suivante : 
```bash
conda create --name noise2noise python=3.10.8
```
- Pour activer l'environnement :
```bash
conda activate noise2noise
```
- Pour accÃ©der au rÃ©pertoire : 
```bash
cd desktop # affichera sur votre Bureau d'ordinateur 
git clone https://gitlab-student.centralesupelec.fr/albane.michot/DeepLearning_Project.git
cd DeepLearning_Project
```

2. Vous devez ensuite installer tous les `requirements` en utilisant la commande suivante :
```bash
conda install --file requirements.txt
```

ExÃ©cuter ensuite les notebooks jupyter dans l'ordre suivant : 

1. Data_augmentation.ipynb 
2. filters.ipynb
3. Noise2Noise_ResNet.ipynb
4. Noise2Noise_UNet.ipynb
5. Inverse_Noise2Noise_Discriminative.ipynb

## :pencil2: Auteurs
- MICHOT Albane
- NONCLERCQ Rodolphe



